{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Univariate Time Series Forecasting using LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrySSdtE7QmW"
      },
      "source": [
        "###Univariate Time Series Forecasting using LSTM\n",
        "\n",
        "The next value is predicted depending upon the last 3 values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10aJUEtK7Qma"
      },
      "source": [
        "\n",
        "# univariate lstm example\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj-XBuFO7Qmb"
      },
      "source": [
        "# preparing independent and dependent features\n",
        "def prepare_data(timeseries_data, n_features):\n",
        "\tX, y =[],[]\n",
        "\tfor i in range(len(timeseries_data)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_features\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(timeseries_data)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn np.array(X), np.array(y)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtJrdwHV7Qmb"
      },
      "source": [
        "# define input sequence\n",
        "timeseries_data = [110, 125, 133, 146, 158, 172, 187, 196, 210]\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# split into samples\n",
        "X, y = prepare_data(timeseries_data, n_steps)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu2tA4_b7Qmc",
        "outputId": "02300cbf-619d-4020-c349-68c498ecb613"
      },
      "source": [
        "print(X),print(y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[110 125 133]\n",
            " [125 133 146]\n",
            " [133 146 158]\n",
            " [146 158 172]\n",
            " [158 172 187]\n",
            " [172 187 196]]\n",
            "[146 158 172 187 196 210]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Nc-yet-7Qmd",
        "outputId": "6b8286a5-5906-4dfa-c03c-38d42b2ef2cc"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI0Oqxaq7Qmd"
      },
      "source": [
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_ehl6t47Qme"
      },
      "source": [
        "### Building LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZotfPF47Qme",
        "outputId": "4abda18b-8ed7-40f9-92ae-f0f0e7f9c299"
      },
      "source": [
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=300, verbose=1)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/300\n",
            "1/1 [==============================] - 5s 5s/step - loss: 28718.0156\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 28404.6777\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 28089.4004\n",
            "Epoch 4/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 27772.3613\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 27454.2559\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 27134.1875\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 26809.1406\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 26470.5859\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 26122.8340\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 25768.7910\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 25410.3438\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 25053.0215\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 24702.0059\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 24357.8984\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 24016.5410\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 23671.0938\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 23315.8535\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 22939.8105\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 22545.6855\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 22130.0371\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 21690.6348\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 21222.3496\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 20714.5996\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 20148.1973\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 19489.6953\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18692.8672\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 17763.7812\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 16785.3770\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 15773.2627\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 14617.4326\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 13092.9619\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 11080.8291\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8616.9336\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 5777.3789\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3170.2898\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1521.1107\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 671.5287\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 189.9925\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 12.3683\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 210.8166\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 600.9758\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 922.4276\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1027.8141\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 933.3334\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 780.5266\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 617.8817\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 451.0102\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 291.4412\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 158.9351\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 64.7544\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 16.8385\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 15.2032\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 44.3168\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 84.2121\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 119.9658\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 142.5136\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 148.7356\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 140.1976\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 120.9550\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 95.7855\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 69.2652\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 45.3186\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 26.8633\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 15.4744\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.2138\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 12.8592\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 18.3899\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 25.5052\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 32.0919\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 36.5700\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 38.0767\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 36.5062\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 32.4593\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 27.0736\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 21.6405\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 17.1109\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 13.9066\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 12.0213\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 11.1649\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 11.1040\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 11.6642\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 12.5528\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 13.4220\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14.0615\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 14.4354\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 14.5465\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 14.3790\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 13.9476\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 13.3213\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 12.6058\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 11.9141\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11.3412\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 10.9476\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 10.7531\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 10.7390\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 10.8573\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 11.0447\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 11.2368\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 11.3806\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 11.4427\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 11.4124\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 11.3003\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 11.1318\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 10.9400\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 10.7575\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 10.6099\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 10.5115\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 10.4651\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 10.4623\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 10.4879\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 10.5239\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 10.5535\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 10.5645\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 10.5512\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 10.5139\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 10.4585\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 10.3937\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 10.3292\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 10.2728\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 10.2301\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 10.2022\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 10.1876\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 10.1816\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 10.1791\n",
            "Epoch 125/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 10.1746\n",
            "Epoch 126/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 10.1644\n",
            "Epoch 127/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 10.1465\n",
            "Epoch 128/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 10.1214\n",
            "Epoch 129/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 10.0912\n",
            "Epoch 130/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 10.0587\n",
            "Epoch 131/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 10.0273\n",
            "Epoch 132/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 9.9990\n",
            "Epoch 133/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 9.9752\n",
            "Epoch 134/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.9557\n",
            "Epoch 135/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.9394\n",
            "Epoch 136/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 9.9244\n",
            "Epoch 137/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 9.9088\n",
            "Epoch 138/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 9.8912\n",
            "Epoch 139/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 9.8701\n",
            "Epoch 140/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 9.8453\n",
            "Epoch 141/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 9.8161\n",
            "Epoch 142/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.7820\n",
            "Epoch 143/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 9.7411\n",
            "Epoch 144/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 9.6902\n",
            "Epoch 145/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.6252\n",
            "Epoch 146/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 9.5465\n",
            "Epoch 147/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.4781\n",
            "Epoch 148/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.5105\n",
            "Epoch 149/300\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.4584\n",
            "Epoch 150/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.3598\n",
            "Epoch 151/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.3179\n",
            "Epoch 152/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.3070\n",
            "Epoch 153/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.2868\n",
            "Epoch 154/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 9.2389\n",
            "Epoch 155/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.1660\n",
            "Epoch 156/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 9.1064\n",
            "Epoch 157/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 9.1056\n",
            "Epoch 158/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 9.0706\n",
            "Epoch 159/300\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.9937\n",
            "Epoch 160/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.9623\n",
            "Epoch 161/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.9457\n",
            "Epoch 162/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.8969\n",
            "Epoch 163/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 8.8315\n",
            "Epoch 164/300\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.7992\n",
            "Epoch 165/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.7719\n",
            "Epoch 166/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 8.7040\n",
            "Epoch 167/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.6550\n",
            "Epoch 168/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.6177\n",
            "Epoch 169/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 8.5530\n",
            "Epoch 170/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.4743\n",
            "Epoch 171/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.4016\n",
            "Epoch 172/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 8.2849\n",
            "Epoch 173/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 8.1004\n",
            "Epoch 174/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.8460\n",
            "Epoch 175/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.4861\n",
            "Epoch 176/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.1515\n",
            "Epoch 177/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.4037\n",
            "Epoch 178/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 6.7511\n",
            "Epoch 179/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.9419\n",
            "Epoch 180/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.9990\n",
            "Epoch 181/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.6426\n",
            "Epoch 182/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.2913\n",
            "Epoch 183/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.6550\n",
            "Epoch 184/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.0769\n",
            "Epoch 185/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.0019\n",
            "Epoch 186/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.0637\n",
            "Epoch 187/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 5.7190\n",
            "Epoch 188/300\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.4879\n",
            "Epoch 189/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.5961\n",
            "Epoch 190/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.1829\n",
            "Epoch 191/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.2199\n",
            "Epoch 192/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.1048\n",
            "Epoch 193/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.8637\n",
            "Epoch 194/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.9840\n",
            "Epoch 195/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.7117\n",
            "Epoch 196/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.7310\n",
            "Epoch 197/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 4.6576\n",
            "Epoch 198/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.4969\n",
            "Epoch 199/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.5632\n",
            "Epoch 200/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.3605\n",
            "Epoch 201/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.4195\n",
            "Epoch 202/300\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.2612\n",
            "Epoch 203/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.3179\n",
            "Epoch 204/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4.1823\n",
            "Epoch 205/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.2251\n",
            "Epoch 206/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.1354\n",
            "Epoch 207/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.1755\n",
            "Epoch 208/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.0815\n",
            "Epoch 209/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.1220\n",
            "Epoch 210/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.0412\n",
            "Epoch 211/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.0819\n",
            "Epoch 212/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.0022\n",
            "Epoch 213/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.0254\n",
            "Epoch 214/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.9707\n",
            "Epoch 215/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.9895\n",
            "Epoch 216/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.9536\n",
            "Epoch 217/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.9583\n",
            "Epoch 218/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.9360\n",
            "Epoch 219/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.9278\n",
            "Epoch 220/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.9153\n",
            "Epoch 221/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.8947\n",
            "Epoch 222/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.8936\n",
            "Epoch 223/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.8653\n",
            "Epoch 224/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.8715\n",
            "Epoch 225/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.8461\n",
            "Epoch 226/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.8472\n",
            "Epoch 227/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.8332\n",
            "Epoch 228/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.8177\n",
            "Epoch 229/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.8162\n",
            "Epoch 230/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.7940\n",
            "Epoch 231/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.7897\n",
            "Epoch 232/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.7782\n",
            "Epoch 233/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.7641\n",
            "Epoch 234/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.7608\n",
            "Epoch 235/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.7455\n",
            "Epoch 236/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.7378\n",
            "Epoch 237/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.7299\n",
            "Epoch 238/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.7154\n",
            "Epoch 239/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.7094\n",
            "Epoch 240/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.6995\n",
            "Epoch 241/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.6871\n",
            "Epoch 242/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.6812\n",
            "Epoch 243/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.6721\n",
            "Epoch 244/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.6601\n",
            "Epoch 245/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.6531\n",
            "Epoch 246/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.6450\n",
            "Epoch 247/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.6334\n",
            "Epoch 248/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.6248\n",
            "Epoch 249/300\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.6177\n",
            "Epoch 250/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.6079\n",
            "Epoch 251/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.5979\n",
            "Epoch 252/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.5904\n",
            "Epoch 253/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.5825\n",
            "Epoch 254/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.5728\n",
            "Epoch 255/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.5634\n",
            "Epoch 256/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.5556\n",
            "Epoch 257/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.5478\n",
            "Epoch 258/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.5388\n",
            "Epoch 259/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.5296\n",
            "Epoch 260/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.5211\n",
            "Epoch 261/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.5132\n",
            "Epoch 262/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.5053\n",
            "Epoch 263/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.4970\n",
            "Epoch 264/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.4883\n",
            "Epoch 265/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.4795\n",
            "Epoch 266/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.4709\n",
            "Epoch 267/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.4627\n",
            "Epoch 268/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.4547\n",
            "Epoch 269/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.4468\n",
            "Epoch 270/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.4390\n",
            "Epoch 271/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.4313\n",
            "Epoch 272/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.4240\n",
            "Epoch 273/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.4176\n",
            "Epoch 274/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.4128\n",
            "Epoch 275/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.4129\n",
            "Epoch 276/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.4211\n",
            "Epoch 277/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.4543\n",
            "Epoch 278/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.5001\n",
            "Epoch 279/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.5743\n",
            "Epoch 280/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.4831\n",
            "Epoch 281/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.3730\n",
            "Epoch 282/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.3623\n",
            "Epoch 283/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.4276\n",
            "Epoch 284/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.4278\n",
            "Epoch 285/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.3363\n",
            "Epoch 286/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.3438\n",
            "Epoch 287/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.3979\n",
            "Epoch 288/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.3468\n",
            "Epoch 289/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.2988\n",
            "Epoch 290/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.3246\n",
            "Epoch 291/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.3366\n",
            "Epoch 292/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.3002\n",
            "Epoch 293/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2732\n",
            "Epoch 294/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.2924\n",
            "Epoch 295/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.3009\n",
            "Epoch 296/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.2655\n",
            "Epoch 297/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2478\n",
            "Epoch 298/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2611\n",
            "Epoch 299/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.2592\n",
            "Epoch 300/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.2361\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc1b0687050>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPCdUeS97Qmf"
      },
      "source": [
        "### Predicting For the next 10 data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdO9C8VV7Qmf",
        "outputId": "16a077db-0d43-4241-bb51-d2e982b10586"
      },
      "source": [
        "# demonstrate prediction for next 10 days\n",
        "x_input = np.array([187, 196, 210])\n",
        "temp_input=list(x_input)\n",
        "lst_output=[]\n",
        "i=0\n",
        "while(i<10):\n",
        "    \n",
        "    if(len(temp_input)>3):\n",
        "        x_input=np.array(temp_input[1:])\n",
        "        print(\"{} day input {}\".format(i,x_input))\n",
        "        #print(x_input)\n",
        "        x_input = x_input.reshape((1, n_steps, n_features))\n",
        "        #print(x_input)\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(\"{} day output {}\".format(i,yhat))\n",
        "        temp_input.append(yhat[0][0])\n",
        "        temp_input=temp_input[1:]\n",
        "        #print(temp_input)\n",
        "        lst_output.append(yhat[0][0])\n",
        "        i=i+1\n",
        "    else:\n",
        "        x_input = x_input.reshape((1, n_steps, n_features))\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(yhat[0])\n",
        "        temp_input.append(yhat[0][0])\n",
        "        lst_output.append(yhat[0][0])\n",
        "        i=i+1\n",
        "    \n",
        "\n",
        "print(lst_output)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[225.16872]\n",
            "1 day input [196.         210.         225.16871643]\n",
            "1 day output [[236.3317]]\n",
            "2 day input [210.         225.16871643 236.33169556]\n",
            "2 day output [[250.52321]]\n",
            "3 day input [225.16872 236.3317  250.52321]\n",
            "3 day output [[265.3227]]\n",
            "4 day input [236.3317  250.52321 265.3227 ]\n",
            "4 day output [[278.426]]\n",
            "5 day input [250.52321 265.3227  278.426  ]\n",
            "5 day output [[293.39435]]\n",
            "6 day input [265.3227  278.426   293.39435]\n",
            "6 day output [[308.76105]]\n",
            "7 day input [278.426   293.39435 308.76105]\n",
            "7 day output [[323.74698]]\n",
            "8 day input [293.39435 308.76105 323.74698]\n",
            "8 day output [[339.97122]]\n",
            "9 day input [308.76105 323.74698 339.97122]\n",
            "9 day output [[356.63657]]\n",
            "[225.16872, 236.3317, 250.52321, 265.3227, 278.426, 293.39435, 308.76105, 323.74698, 339.97122, 356.63657]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naP9FLK07Qmg",
        "outputId": "644bc694-6a2c-45d2-f89e-32d845ade397"
      },
      "source": [
        "timeseries_data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[110, 125, 133, 146, 158, 172, 187, 196, 210]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO8hXDQT7Qmg",
        "outputId": "8635f97c-6beb-4bfd-f9b5-c560320a9d14"
      },
      "source": [
        "len(timeseries_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF6xH8fH7Qmh",
        "outputId": "35a1e868-40f7-4c42-c355-f55df59d63f2"
      },
      "source": [
        "lst_output"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[225.16872,\n",
              " 236.3317,\n",
              " 250.52321,\n",
              " 265.3227,\n",
              " 278.426,\n",
              " 293.39435,\n",
              " 308.76105,\n",
              " 323.74698,\n",
              " 339.97122,\n",
              " 356.63657]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZuYnYdy7Qmh"
      },
      "source": [
        "### Visualizaing The Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOPCqiyL7Qmh"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCMGFRrA7Qmh"
      },
      "source": [
        "day_new=np.arange(1,10)\n",
        "day_pred=np.arange(10,20)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "hHf9TbZD7Qmi",
        "outputId": "d6b47fe7-9e72-4c0c-a2e7-111acd89e13f"
      },
      "source": [
        "plt.plot(day_new,timeseries_data)\n",
        "plt.plot(day_pred,lst_output)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc1b0721110>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU6g9Tjp7Qmi"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}